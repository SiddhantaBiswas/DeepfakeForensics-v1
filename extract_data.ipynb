{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from src.preprocessing_util import *\n",
    "from src.util import create_train_test_sets\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we need to setup data folders\n",
    "\n",
    "Required:\n",
    "\n",
    "1. Path to raw data\n",
    "2. Path to store non-augmented data\n",
    "3. Path to store augmented data\n",
    "\n",
    "The raw data directory should contain two subfolders, called \"real\" and \"fake\", and should hold the videos belonging to that category. So in the special case of the Celeb-DF:\n",
    "\n",
    "Place the videos from \"Celeb-real\" and \"YouTube-real\" into the \"real\" folder. \\\n",
    "Place the videos from \"Celeb-synthesis\" into the \"fake\" folder.\n",
    "\n",
    "We specify whether the derived dataset should be aimed at training temporal, or non-temporal models. Currently, both model types can only be trained using their respective dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_raw_data = 'raw_data/' # path to raw data\n",
    "\n",
    "temporal = False\n",
    "\n",
    "path_to_store_faces = f'data/{\"temporal\" if temporal else \"nontemp\"}/faces/'           # path to store non-augmented data\n",
    "path_to_store_faces_aug = f'data/{\"temporal\" if temporal else \"nontemp\"}/faces_aug/'   # path to store augmented data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First load the face detection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face detector\n",
    "face_detector = MTCNN(image_size=224, margin=10, keep_all=False, device=device, post_process=False).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "Specify the amount of frames extracted per real file. If this is adapted, this needs to be changed as well separately for fake files.\n",
    "\n",
    "E.g. for the Celeb-DF dataset:\n",
    "\n",
    "There are 890 real files: 890 * 65 = 57.850\n",
    "There are 5.639 fake files: 5.639 * 10 = 56.390\n",
    "\n",
    "So the current configuration results in a balanced dataset. Note that only multiples of 5 can be selected when extracting temporal data, because the sequence length for the face sequences is set to 5 for the LSTM.\n",
    "\n",
    "Also, a minimum face detection threshold can be set to disregard files which result in a large proportion of frames not detecting any faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 65\n",
    "min_face_cutoff = 32\n",
    "\n",
    "# Load facial detection pipeline\n",
    "face_detection = FaceDetection(face_detector, device, n_frames=n_frames)\n",
    "\n",
    "# enable logging plots, if this is true, no face images will be saved, just the plots\n",
    "log_plots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the dataset\n",
    "Extract one subfolder after another. We keep track of the labels for each datapoint via stored csv files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting  faces from 890 Real files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef8cbd6b533489cb40e62f7768a1e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=890.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has less than 65 frames. Skipping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# real folder\n",
    "path_to_folder =  path_to_raw_data + 'real/'\n",
    "name_csv = 'real'\n",
    "label = 'Real'\n",
    "\n",
    "labels = get_CDF_per_folder(path_to_data=path_to_folder,\n",
    "                            path_to_store_faces=path_to_store_faces,\n",
    "                            path_to_store_faces_aug=path_to_store_faces_aug,\n",
    "                            face_detection=face_detection,\n",
    "                            label=label,\n",
    "                            csv_file_name=name_csv,\n",
    "                            min_face_cutoff=min_face_cutoff,\n",
    "                            temporal = temporal,\n",
    "                            log_plots=log_plots,\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now derived data from all real files. Next we need to derive data from the fake files.\n",
    "As mentioned, this needs to be done with different number of frames per file, to ensure a balanced dataset.\n",
    "Make sure both n_frame instances produce an even amount of datapoints (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to initialize a new face detection model for smaller amount of frames\n",
    "n_frames = 10\n",
    "min_face_cutoff = 5\n",
    "face_detection = FaceDetection(face_detector, device, n_frames=n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting  faces from 5639 Fake files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310895398c33476ba0d09fa11afa5a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5639.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# synthesis folder\n",
    "path_to_folder =  path_to_raw_data + 'fake/'\n",
    "name_csv = 'fake'\n",
    "label = 'Fake'\n",
    "\n",
    "labels = get_CDF_per_folder(path_to_data=path_to_folder,\n",
    "                            path_to_store_faces=path_to_store_faces,\n",
    "                            path_to_store_faces_aug=path_to_store_faces_aug,\n",
    "                            face_detection=face_detection,\n",
    "                            label=label,\n",
    "                            csv_file_name=name_csv,\n",
    "                            min_face_cutoff=min_face_cutoff,\n",
    "                            temporal = temporal,\n",
    "                            log_plots=log_plots,\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label merging\n",
    "For each folder, we have a respective label file. Those need to be merged.\n",
    "For each dataset, we handle two different types of labels.\n",
    "\n",
    "1. Per file labels\n",
    "2. Per datapoint labels (per face image for non-temporal models, per face-window for temporal models)\n",
    "\n",
    "\n",
    "First we merge the labels on file-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>id9_id6_0005.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>id9_id6_0006.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>id9_id6_0007.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>id9_id6_0008.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6528 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  label\n",
       "0            00000.mp4      0\n",
       "1            00001.mp4      0\n",
       "2            00002.mp4      0\n",
       "3            00003.mp4      0\n",
       "4            00004.mp4      0\n",
       "...                ...    ...\n",
       "6523  id9_id6_0005.mp4      1\n",
       "6524  id9_id6_0006.mp4      1\n",
       "6525  id9_id6_0007.mp4      1\n",
       "6526  id9_id6_0008.mp4      1\n",
       "6527  id9_id6_0009.mp4      1\n",
       "\n",
       "[6528 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Labels/\"\n",
    "file1 = \"real_labels_per_file.csv\"\n",
    "file2 = \"fake_labels_per_file.csv\"\n",
    "\n",
    "\n",
    "\n",
    "labels_per_file = combine_labels(path, file1, file2)\n",
    "labels_per_file.to_csv(\"Labels/labels_per_file.csv\")\n",
    "labels_per_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we merge the labels on datapoint-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000_00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001_00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003_00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004_00000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114153</th>\n",
       "      <td>005_id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114154</th>\n",
       "      <td>006_id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114155</th>\n",
       "      <td>007_id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114156</th>\n",
       "      <td>008_id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114157</th>\n",
       "      <td>009_id9_id6_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114158 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file  label\n",
       "0              000_00000.mp4      0\n",
       "1              001_00000.mp4      0\n",
       "2              002_00000.mp4      0\n",
       "3              003_00000.mp4      0\n",
       "4              004_00000.mp4      0\n",
       "...                      ...    ...\n",
       "114153  005_id9_id6_0009.mp4      1\n",
       "114154  006_id9_id6_0009.mp4      1\n",
       "114155  007_id9_id6_0009.mp4      1\n",
       "114156  008_id9_id6_0009.mp4      1\n",
       "114157  009_id9_id6_0009.mp4      1\n",
       "\n",
       "[114158 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Labels/\"\n",
    "file1 = f\"real_labels_per_{'face' if not temporal else 'face_window'}.csv\"\n",
    "file2 = f\"fake_labels_per_{'face' if not temporal else 'face_window'}.csv\"\n",
    "\n",
    "labels_per_face = combine_labels(path, file1, file2)\n",
    "labels_per_face.to_csv(f\"Labels/labels_per_{'face' if not temporal else 'face_window'}.csv\")\n",
    "labels_per_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create splits\n",
    "\n",
    "Now that we have the datasets and labels, we can perform the train/val/test split. We do this on file level.\n",
    "For this, we can adapt the size of the training set. The resulting proportion of the dataset will be evenly split into validation/testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the split. The resulting label files per split will be stored in the root folders where the data is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving the correct face labels for the split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95333926c3b9471fbd4d8586c73728a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Per face labelling derived for split:\n",
      "                         file  label\n",
      "0      006_id23_id29_0001.mp4      1\n",
      "1      002_id23_id29_0001.mp4      1\n",
      "2      003_id23_id29_0001.mp4      1\n",
      "3      008_id23_id29_0001.mp4      1\n",
      "4      005_id23_id29_0001.mp4      1\n",
      "...                       ...    ...\n",
      "91911    002_id8_id9_0008.mp4      1\n",
      "91912    008_id8_id9_0008.mp4      1\n",
      "91913    007_id8_id9_0008.mp4      1\n",
      "91914    004_id8_id9_0008.mp4      1\n",
      "91915    000_id8_id9_0008.mp4      1\n",
      "\n",
      "[91916 rows x 2 columns]\n",
      "\n",
      "Per window labelling for split:\n",
      "                    file  label\n",
      "3858  id23_id29_0001.mp4      1\n",
      "2441           00052.mp4      0\n",
      "94    id31_id17_0003.mp4      1\n",
      "4954  id54_id49_0003.mp4      1\n",
      "4109       id49_0008.mp4      0\n",
      "...                  ...    ...\n",
      "1546           00096.mp4      0\n",
      "389   id54_id52_0008.mp4      1\n",
      "4374  id19_id27_0007.mp4      1\n",
      "5305    id0_id1_0009.mp4      1\n",
      "1823    id8_id9_0008.mp4      1\n",
      "\n",
      "[5222 rows x 2 columns]\n",
      "Finished split train/!\n",
      "Deriving the correct face labels for the split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bac13deeaca470ca016ee2712649521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=653.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Per face labelling derived for split:\n",
      "                         file  label\n",
      "0       004_id6_id26_0005.mp4      1\n",
      "1       007_id6_id26_0005.mp4      1\n",
      "2       008_id6_id26_0005.mp4      1\n",
      "3       001_id6_id26_0005.mp4      1\n",
      "4       006_id6_id26_0005.mp4      1\n",
      "...                       ...    ...\n",
      "10705  008_id46_id43_0003.mp4      1\n",
      "10706  004_id46_id43_0003.mp4      1\n",
      "10707  009_id46_id43_0003.mp4      1\n",
      "10708  000_id46_id43_0003.mp4      1\n",
      "10709  001_id46_id43_0003.mp4      1\n",
      "\n",
      "[10710 rows x 2 columns]\n",
      "\n",
      "Per window labelling for split:\n",
      "                    file  label\n",
      "3710   id6_id26_0005.mp4      1\n",
      "241    id4_id37_0009.mp4      1\n",
      "1993  id20_id21_0009.mp4      1\n",
      "6012       id25_0002.mp4      0\n",
      "4790       id17_0005.mp4      0\n",
      "...                  ...    ...\n",
      "3673  id57_id50_0005.mp4      1\n",
      "5297    id8_id7_0008.mp4      1\n",
      "1668  id23_id20_0009.mp4      1\n",
      "2667       id48_0001.mp4      0\n",
      "3530  id46_id43_0003.mp4      1\n",
      "\n",
      "[653 rows x 2 columns]\n",
      "Finished split val/!\n",
      "Deriving the correct face labels for the split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a831a98cae74d09826e5a7ea64369b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=653.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Per face labelling derived for split:\n",
      "                        file  label\n",
      "0      004_id7_id11_0004.mp4      1\n",
      "1      009_id7_id11_0004.mp4      1\n",
      "2      000_id7_id11_0004.mp4      1\n",
      "3      007_id7_id11_0004.mp4      1\n",
      "4      001_id7_id11_0004.mp4      1\n",
      "...                      ...    ...\n",
      "11527   009_id9_id0_0000.mp4      1\n",
      "11528   007_id9_id0_0000.mp4      1\n",
      "11529   005_id9_id0_0000.mp4      1\n",
      "11530   008_id9_id0_0000.mp4      1\n",
      "11531   000_id9_id0_0000.mp4      1\n",
      "\n",
      "[11532 rows x 2 columns]\n",
      "\n",
      "Per window labelling for split:\n",
      "                    file  label\n",
      "5705   id7_id11_0004.mp4      1\n",
      "3368  id16_id21_0012.mp4      1\n",
      "1207  id52_id56_0002.mp4      1\n",
      "1852  id44_id46_0000.mp4      1\n",
      "6409    id8_id6_0008.mp4      1\n",
      "...                  ...    ...\n",
      "3815  id21_id29_0007.mp4      1\n",
      "4110  id30_id17_0000.mp4      1\n",
      "227         id2_0009.mp4      0\n",
      "1343   id23_id2_0005.mp4      1\n",
      "2797    id9_id0_0000.mp4      1\n",
      "\n",
      "[653 rows x 2 columns]\n",
      "Finished split test/!\n"
     ]
    }
   ],
   "source": [
    "labels_per_file = 'Labels/labels_per_file.csv'\n",
    "labels_per_face = 'Labels/labels_per_face.csv'\n",
    "\n",
    "\n",
    "create_train_test_sets(labels_per_file=labels_per_file,\n",
    "                       labels_per_face=labels_per_face,\n",
    "                       root_dir=path_to_store_faces,\n",
    "                       root_dir_aug=path_to_store_faces_aug,\n",
    "                       train_size=train_size,\n",
    "                       temporal=temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, because in the end, we want to predict on video-level, we create a subfolder in our datafolder holding the video sequences associated with the testsplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frede\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70229ec88cdb48c0a89369423f62bbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testlabels = pd.read_csv(f\"data/{'temporal' if temporal else 'nontemp'}/faces/testlabels_per_file.csv\" , index_col=0) \n",
    "\n",
    "# only select en equal amount of positive and negative files\n",
    "real_labels = testlabels.loc[testlabels.label == 0]\n",
    "fake_labels = testlabels.loc[testlabels.label == 1].sample(n=len(real_labels))\n",
    "\n",
    "testlabels = pd.concat([real_labels, fake_labels])\n",
    "    \n",
    "\n",
    "target_dir_real = f\"data/{'temporal' if temporal else 'nontemp'}/testfiles/real/\"\n",
    "target_dir_fake = f\"data/{'temporal' if temporal else 'nontemp'}/testfiles/fake/\"\n",
    "    \n",
    "\n",
    "for subpath in [target_dir_real, target_dir_fake]:                \n",
    "    if not os.path.exists(subpath):\n",
    "        os.makedirs(subpath)\n",
    "\n",
    "\n",
    "for row in tqdm(testlabels.iterrows()): \n",
    "    target_dir = target_dir_fake if row[1][1] == 1 else target_dir_real\n",
    "    try:\n",
    "        copyfile(path_to_raw_data + 'real/' + row[1][0], target_dir + row[1][0])\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            copyfile(path_to_raw_data + 'fake/' + row[1][0], target_dir + row[1][0])\n",
    "        except FileNotFoundError:\n",
    "            print(f'whoops, did not find file {row[1][0]} at all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
